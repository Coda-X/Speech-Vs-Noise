# Speech-Vs-Noise AI Project
This project is my journey to build an AI model that can separate human speech from background noise. 
The idea comes from personal experience with hearing loss in my family, and my hope is to explore how math + technology can make sound clearer for people who need it most. 

Day 1 - Environment Setup
- Installed Python 3.12
- Installed VSCode for coding and Git integration
- Set up Github desktop for version control
- Created a repository and made my first commit

Day 2 - Dataset and First visualization
- Downloaded urbansound8k dataset
- Organized project structure
   - data/speech: placehodler for speech samples
   - data/noise: contains background noise samples
- Created first Python script: day2_visualize.py
   - Loads an audio file with Librosa
   - Visualizes sound as a waveform using Matplotlib
   - Visualized dog bark as a waveform

- Day 2 was about preparing data and making audio visible for the first time.
- Seeing the waveform of a dog bark helped me realize that sound is just numbers.
- Those numbers can be turned into patterns that could be analyzed and that a machine can learn.


Day 3 - 

